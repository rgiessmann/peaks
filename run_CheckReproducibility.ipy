# coding: utf-8

# In[1]:
# -------------------------------- #
### set plotting options
get_ipython().magic(u'matplotlib')
# -------------------------------- #


# In[2]:
# -------------------------------- #
## import code for data processing
import peaks.footprint
footprint = peaks.footprint.Footprinter() 
# -------------------------------- #


# In[3]:
# -------------------------------- #
### Import metadata for 'Peak Scanner 2' output
trace_list = footprint.get_data("./input_traces.csv")
# -------------------------------- #


# In[21]:
# -------------------------------- #
### Set options
## accepted_offset: peaks are clustered, if their size (=bp) lies within this difference (in bp)
## factor_method: if "num" look for optimal factor (free-floating), if "peak" find a footprinting-insensitive peak
## weight_smaller/weight_bigger: importance of misfit peaks which are smaller / bigger than reference peaks
## relative_mode: if "True" determine the importance of misfit peaks due to their relative size compared to the reference peak, if "False" consider absolute difference (in AU)
## from_bp/ to_bp: peaks in this interval of sizes (=bp) shall be considered for analysis.

_accepted_offset = 0.5
_factor_method   = "num"
_weight_smaller  = 1
_weight_bigger   = 1
_relative_mode   = 0.9999
_from_bp         = 0
_to_bp           = 200

### Generate the reference trace
ref = footprint.generate_averaged_negative_control(trace_list,accepted_offset=_accepted_offset,factor_method=_factor_method, weight_smaller=0.5, weight_bigger=0.5, relative_mode=_relative_mode, from_bp=_from_bp, to_bp=_to_bp, normalize_to=None)
# -------------------------------- #


# In[22]:
# -------------------------------- #
footprint.cluster_peaks(ref,trace_list,accepted_offset=_accepted_offset)

df = footprint.check_which_peaks_to_optimize(ref, trace_list, weight_smaller=_weight_smaller, weight_bigger=_weight_bigger, relative_mode=_relative_mode, from_bp=_from_bp, to_bp=_to_bp)
df.to_csv("check_peaks.csv")





# In[30]:
# -------------------------------- #
### Determine factor for height adjustment by finding an optimal invariant peak

#_factor_method   = "peak"
#optimal_factors = footprint.determine_factor_single_peak(ref, trace_list, weight_smaller=_weight_smaller, weight_bigger=_weight_bigger, relative_mode=_relative_mode, from_bp=_from_bp, to_bp=_to_bp)

#_factor_method   = "num"
optimal_factors = footprint.determine_factor_numerically(ref, trace_list, weight_smaller=_weight_smaller, weight_bigger=_weight_bigger, relative_mode=_relative_mode, from_bp=_from_bp, to_bp=_to_bp)

### Correct traces with optimal factors 
for index, null in enumerate(trace_list):
    footprint.correct_peaks_with_factor(trace_list[index],optimal_factors[index])
    print("file: {:30.30} --> factor: {:4.2f}".format(trace_list[index].file_name, optimal_factors[index]))
# -------------------------------- #

import pandas 
df_big=None
for trace in trace_list:
    bigdict={} 
    clusterlist=[]
    heightlist=[]
    for peak in trace.peaks:
        if getattr(peak, "cluster", 0)!=0:
            clusterlist.append(peak.cluster)
            heightlist.append(peak.peak_height)
    # print(clusterlist, heightlist)
    bigdict.update({"cluster" : clusterlist, trace.file_name : heightlist})
    df_small=pandas.DataFrame.from_dict(bigdict)
    # print df_small
    if not df_big is None:
        df_big = df_big.merge(df_small, on="cluster", how="outer")
    else:
        df_big=df_small
df_big.to_csv("check-reproducibility-peakheights.csv")
